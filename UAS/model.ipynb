{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Proyek Klasifikasi Gambar dengan CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Lingkungan Pengembangan**\n",
    "- **Bahasa Pemrograman**: Python\n",
    "- **Framework**: TensorFlow dan Keras\n",
    "- **Dataset**: Dataset gambar dengan kategori sampah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tahapan Implementasi**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap pertama adalah membagi dataset menjadi dua bagian utama:\n",
    "- **Training Set**: Digunakan untuk melatih model, mencakup 80% dari total data.\n",
    "- **Validation Set**: Digunakan untuk mengevaluasi performa model selama pelatihan, mencakup 20% dari total data.\n",
    "\n",
    "Pembagian dataset dilakukan secara terstruktur ke dalam folder sesuai kategori, sehingga setiap kategori memiliki direktori terpisah untuk data pelatihan dan validasi. Struktur ini membantu dalam proses pemuatan data oleh generator gambar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path dataset asli\n",
    "original_dataset_dir = \"dataset\" \n",
    "output_train_dir = \"dataset_split/train\"\n",
    "output_val_dir = \"dataset_split/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_train_dir, exist_ok=True)\n",
    "os.makedirs(output_val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil split dataset\n"
     ]
    }
   ],
   "source": [
    "categories = os.listdir(original_dataset_dir)  # Folder kategori\n",
    "for category in categories:\n",
    "    category_path = os.path.join(original_dataset_dir, category)\n",
    "    if not os.path.isdir(category_path):\n",
    "        continue\n",
    "\n",
    "    # Ambil semua file dalam kategori\n",
    "    images = os.listdir(category_path)\n",
    "\n",
    "    # Split dataset menjadi train dan validation (80%-20%)\n",
    "    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Path output untuk setiap kategori\n",
    "    train_category_dir = os.path.join(output_train_dir, category)\n",
    "    val_category_dir = os.path.join(output_val_dir, category)\n",
    "\n",
    "    # Membuat folder kategori di train dan validation\n",
    "    os.makedirs(train_category_dir, exist_ok=True)\n",
    "    os.makedirs(val_category_dir, exist_ok=True)\n",
    "\n",
    "    # Pindahkan file ke folder train\n",
    "    for image in train_images:\n",
    "        src = os.path.join(category_path, image)\n",
    "        dst = os.path.join(train_category_dir, image)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Pindahkan file ke folder validation\n",
    "    for image in val_images:\n",
    "        src = os.path.join(category_path, image)\n",
    "        dst = os.path.join(val_category_dir, image)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"Berhasil split dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Preprocessing Dataset**\n",
    "Setelah dataset dibagi, langkah berikutnya adalah melakukan preprocessing pada gambar. Beberapa langkah penting meliputi:\n",
    "- **Rescaling**: Nilai piksel gambar dirubah menjadi skala 0-1 untuk mempercepat pelatihan.\n",
    "- **Augmentasi Data**: Gambar dilatih dengan berbagai transformasi (rotasi, zoom, flipping) untuk meningkatkan kemampuan generalisasi model.\n",
    "\n",
    "Hasil preprocessing ini dihasilkan oleh generator gambar seperti `ImageDataGenerator` yang mendukung augmentasi real-time selama pelatihan.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tinggi\n",
    "IMG_HEIGHT = 128\n",
    "#lebar\n",
    "IMG_WIDTH = 128\n",
    "#jumlah gambar\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    output_train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 508 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = val_datagen.flow_from_directory(\n",
    "    output_val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Membangun Model CNN**\n",
    "Model CNN dirancang dengan beberapa lapisan utama:\n",
    "1. **Convolutional Layers**: Untuk mengekstraksi fitur dari gambar menggunakan filter yang bergerak di atas gambar.\n",
    "2. **Pooling Layers**: Mengurangi dimensi data sambil mempertahankan informasi penting.\n",
    "3. **Fully Connected Layers**: Lapisan akhir untuk menghasilkan prediksi berdasarkan fitur yang diekstraksi.\n",
    "\n",
    "Arsitektur model disusun dengan filter bertahap yang meningkatkan kompleksitas, diikuti dengan dropout untuk mencegah overfitting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model CNN\n",
    "model = Sequential([\n",
    "    Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')  # 6 kategori sampah\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Melatih Model**\n",
    "Pada tahap ini:\n",
    "- Dataset yang telah diproses digunakan untuk melatih model.\n",
    "- Callback seperti **Early Stopping** digunakan untuk menghentikan pelatihan jika validasi loss tidak membaik dalam beberapa epoch, sehingga mencegah overfitting.\n",
    "- Proses pelatihan dilakukan untuk beberapa epoch hingga model mencapai akurasi yang memadai.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 383ms/step - accuracy: 0.2398 - loss: 1.7062 - val_accuracy: 0.3819 - val_loss: 1.5152\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.3646 - loss: 1.5111 - val_accuracy: 0.4173 - val_loss: 1.4377\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.4067 - loss: 1.4073 - val_accuracy: 0.4016 - val_loss: 1.4138\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.4276 - loss: 1.3864 - val_accuracy: 0.3760 - val_loss: 1.4536\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.4130 - loss: 1.3882 - val_accuracy: 0.4272 - val_loss: 1.3326\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.4578 - loss: 1.3418 - val_accuracy: 0.4429 - val_loss: 1.3268\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - accuracy: 0.4787 - loss: 1.3241 - val_accuracy: 0.4449 - val_loss: 1.3291\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.4785 - loss: 1.2809 - val_accuracy: 0.5059 - val_loss: 1.2377\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - accuracy: 0.4864 - loss: 1.2376 - val_accuracy: 0.5256 - val_loss: 1.2186\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.5367 - loss: 1.1841 - val_accuracy: 0.5846 - val_loss: 1.1376\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.5346 - loss: 1.1998 - val_accuracy: 0.4705 - val_loss: 1.2536\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - accuracy: 0.5243 - loss: 1.1712 - val_accuracy: 0.4980 - val_loss: 1.2144\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.5637 - loss: 1.1250 - val_accuracy: 0.5236 - val_loss: 1.2445\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.5686 - loss: 1.1224 - val_accuracy: 0.5295 - val_loss: 1.2283\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 147ms/step - accuracy: 0.5857 - loss: 1.1264 - val_accuracy: 0.5965 - val_loss: 1.0450\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.6089 - loss: 1.0542 - val_accuracy: 0.5709 - val_loss: 1.1004\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.6077 - loss: 1.0069 - val_accuracy: 0.6319 - val_loss: 0.9620\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.6164 - loss: 1.0343 - val_accuracy: 0.5807 - val_loss: 1.0941\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.6268 - loss: 1.0203 - val_accuracy: 0.5945 - val_loss: 0.9866\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - accuracy: 0.6366 - loss: 0.9652 - val_accuracy: 0.6378 - val_loss: 0.9812\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - accuracy: 0.6456 - loss: 0.9623 - val_accuracy: 0.6260 - val_loss: 0.9698\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - accuracy: 0.6619 - loss: 0.9450 - val_accuracy: 0.6220 - val_loss: 0.9925\n"
     ]
    }
   ],
   "source": [
    "# Callback untuk menghentikan pelatihan jika validasi tidak meningkat\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=50,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Evaluasi Model**\n",
    "Evaluasi dilakukan untuk mengukur performa model pada data validasi. Metode ini membantu memahami seberapa baik model dapat menggeneralisasi data yang tidak dilihat selama pelatihan. Metode evaluasi memberikan nilai:\n",
    "- **Loss**: Tingkat kesalahan model.\n",
    "- **Accuracy**: Persentase prediksi yang benar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6124 - loss: 1.0211\n",
      "Validation Loss: 0.9619932770729065\n",
      "Validation Accuracy: 0.6318897604942322\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "loss, accuracy = model.evaluate(val_data)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Prediksi Gambar**\n",
    "Setelah model dilatih, model digunakan untuk memprediksi kategori dari gambar baru. Langkah-langkah prediksi meliputi:\n",
    "1. **Preprocessing Gambar Baru**: Gambar diubah ke ukuran yang sesuai dan di-normalisasi.\n",
    "2. **Prediksi**: Gambar yang telah diproses diberikan ke model untuk menghasilkan prediksi kategori.\n",
    "\n",
    "Prediksi ini membantu dalam memahami bagaimana model mengklasifikasikan gambar di luar data pelatihan.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size):\n",
    "    #gambar dari path\n",
    "    img = load_img(image_path, target_size=target_size) \n",
    "    img_array = img_to_array(img) \n",
    "    img_array = img_array / 255.0  \n",
    "    img_array = np.expand_dims(img_array, axis=0) \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Prediksi: Metal\n"
     ]
    }
   ],
   "source": [
    "image_path = 'kaleng.jpg'\n",
    "processed_image = preprocess_image(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "predictions = model.predict(processed_image)\n",
    "predicted_class = np.argmax(predictions, axis=1) \n",
    "class_labels = ['Cardboard', 'Glass', 'Metal', 'Paper', 'Plastic', 'Trash'] \n",
    "print(f\"Prediksi: {class_labels[predicted_class[0]]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
